{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear Regression\n",
    "\n",
    "Just going to use the closed form solution for linear regression problems (done this before for uni but in matlab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "%pip install numpy\n",
    "%pip install math\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_linear_fuction(X, with_noise = True):\n",
    "    # takes array X and returns array Y\n",
    "    theta = [0,1]\n",
    "    Y = []\n",
    "    # effectively division makes the standard deviation 0.1 instead of one\n",
    "    noise = np.random.randn(len(X))\n",
    "    noise = noise/10\n",
    "    for x in X:\n",
    "        Y += [np.matmul(theta,x)]\n",
    "    return Y if not with_noise else np.add(Y,noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.31688529]\n",
      " [1.         0.43404035]\n",
      " [1.         0.57069165]\n",
      " [1.         0.41951176]\n",
      " [1.         0.83972365]\n",
      " [1.         0.463405  ]\n",
      " [1.         0.67422616]\n",
      " [1.         0.15761886]\n",
      " [1.         0.37207125]\n",
      " [1.         0.37703406]\n",
      " [1.         0.40113793]\n",
      " [1.         0.47281894]\n",
      " [1.         0.38734558]\n",
      " [1.         0.46996111]\n",
      " [1.         0.34926181]\n",
      " [1.         0.42485968]\n",
      " [1.         0.78014041]\n",
      " [1.         0.21197361]\n",
      " [1.         0.43675421]\n",
      " [1.         0.06662577]\n",
      " [1.         0.88328052]\n",
      " [1.         0.51321179]\n",
      " [1.         0.30249493]\n",
      " [1.         0.01832045]\n",
      " [1.         0.69380569]\n",
      " [1.         0.65957893]\n",
      " [1.         0.28207537]\n",
      " [1.         0.77608578]\n",
      " [1.         0.49636329]\n",
      " [1.         0.19550259]\n",
      " [1.         0.60280365]\n",
      " [1.         0.63210173]\n",
      " [1.         0.48936391]\n",
      " [1.         0.55944477]\n",
      " [1.         0.28688359]\n",
      " [1.         0.36918171]\n",
      " [1.         0.55913815]\n",
      " [1.         0.57540874]\n",
      " [1.         0.51589349]\n",
      " [1.         0.79083166]\n",
      " [1.         0.96348249]\n",
      " [1.         0.36679627]\n",
      " [1.         0.86545664]\n",
      " [1.         0.41689549]\n",
      " [1.         0.08339417]\n",
      " [1.         0.323779  ]\n",
      " [1.         0.6388805 ]\n",
      " [1.         0.78431217]\n",
      " [1.         0.06811465]\n",
      " [1.         0.08523924]\n",
      " [1.         0.94958656]\n",
      " [1.         0.5065387 ]\n",
      " [1.         0.36179536]\n",
      " [1.         0.39460477]\n",
      " [1.         0.64651478]\n",
      " [1.         0.62208474]\n",
      " [1.         0.84914611]\n",
      " [1.         0.71189246]\n",
      " [1.         0.95851878]\n",
      " [1.         0.19173885]\n",
      " [1.         0.73744011]\n",
      " [1.         0.2332743 ]\n",
      " [1.         0.29880809]\n",
      " [1.         0.8677173 ]\n",
      " [1.         0.22337616]\n",
      " [1.         0.10200731]\n",
      " [1.         0.08344525]\n",
      " [1.         0.86986443]\n",
      " [1.         0.69879496]\n",
      " [1.         0.71251281]\n",
      " [1.         0.81858382]\n",
      " [1.         0.4892069 ]\n",
      " [1.         0.27305772]\n",
      " [1.         0.65091008]\n",
      " [1.         0.27304403]\n",
      " [1.         0.21022591]\n",
      " [1.         0.64340354]\n",
      " [1.         0.71827737]\n",
      " [1.         0.55095332]\n",
      " [1.         0.48052365]\n",
      " [1.         0.2480413 ]\n",
      " [1.         0.5036996 ]\n",
      " [1.         0.33548514]\n",
      " [1.         0.1531582 ]\n",
      " [1.         0.74201978]\n",
      " [1.         0.38690886]\n",
      " [1.         0.19910574]\n",
      " [1.         0.03075556]\n",
      " [1.         0.97584359]\n",
      " [1.         0.70165328]\n",
      " [1.         0.53494066]\n",
      " [1.         0.38584974]\n",
      " [1.         0.85232793]\n",
      " [1.         0.66662883]\n",
      " [1.         0.47598708]\n",
      " [1.         0.65589227]\n",
      " [1.         0.68241491]\n",
      " [1.         0.55580085]\n",
      " [1.         0.54083027]\n",
      " [1.         0.5926033 ]]\n",
      "[0.31688529 0.43404035 0.57069165 0.41951176 0.83972365 0.463405\n",
      " 0.67422616 0.15761886 0.37207125 0.37703406 0.40113793 0.47281894\n",
      " 0.38734558 0.46996111 0.34926181 0.42485968 0.78014041 0.21197361\n",
      " 0.43675421 0.06662577 0.88328052 0.51321179 0.30249493 0.01832045\n",
      " 0.69380569 0.65957893 0.28207537 0.77608578 0.49636329 0.19550259\n",
      " 0.60280365 0.63210173 0.48936391 0.55944477 0.28688359 0.36918171\n",
      " 0.55913815 0.57540874 0.51589349 0.79083166 0.96348249 0.36679627\n",
      " 0.86545664 0.41689549 0.08339417 0.323779   0.6388805  0.78431217\n",
      " 0.06811465 0.08523924 0.94958656 0.5065387  0.36179536 0.39460477\n",
      " 0.64651478 0.62208474 0.84914611 0.71189246 0.95851878 0.19173885\n",
      " 0.73744011 0.2332743  0.29880809 0.8677173  0.22337616 0.10200731\n",
      " 0.08344525 0.86986443 0.69879496 0.71251281 0.81858382 0.4892069\n",
      " 0.27305772 0.65091008 0.27304403 0.21022591 0.64340354 0.71827737\n",
      " 0.55095332 0.48052365 0.2480413  0.5036996  0.33548514 0.1531582\n",
      " 0.74201978 0.38690886 0.19910574 0.03075556 0.97584359 0.70165328\n",
      " 0.53494066 0.38584974 0.85232793 0.66662883 0.47598708 0.65589227\n",
      " 0.68241491 0.55580085 0.54083027 0.5926033 ]\n"
     ]
    }
   ],
   "source": [
    "# lets say we have 100 sample of x\n",
    "X = np.ones(100), np.random.rand(100)\n",
    "X = np.array(X).transpose()\n",
    "\n",
    "# pretty sure the with noise thing is not working or taking the arg\n",
    "# properly bc regardless its returning with noise ..., unless my matrix\n",
    "# multiplication is wrong in the some_linear_function ...\n",
    "Y = some_linear_fuction(X=X, with_noise=False)\n",
    "\n",
    "print(X)\n",
    "print(np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.26813494  5.54664293]\n"
     ]
    }
   ],
   "source": [
    "# can't get the orientation of the different arrays right to ge tthe answer\n",
    "# even removing noise i'm still getting the wrong answer\n",
    "temp1 = np.linalg.inv(np.linalg.matmul(X,np.transpose(X)))\n",
    "temp2 = np.linalg.matmul(temp1,X)\n",
    "theta = np.linalg.matmul(temp2.transpose(),Y)\n",
    "print(theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
